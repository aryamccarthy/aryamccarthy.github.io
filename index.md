---
layout: page
title: About
---

<!--Hi! I'm Arya McCarthy. -->I am a computer scientist, musician, cyclist, and world politics aficionado. <!--Expatriated from Texas, I've had the good fortune to wander, most recently settling in New York. A constant drive for me is to make the communities we're a part of healthier, effective, and welcoming. I'm convinced that the impossible, the improbable, and the inevitable are separated by your grit, and -->I hope to bridge [the new digital divide](https://hilltopicssmu.wordpress.com/2017/04/08/the-new-digital-divide-language-is-the-impediment-to-information-access/) through understanding humans and their languages.

I am [a research scientist at Google DeepMind](https://research.google/people/aryamccarthy/), expanding its multilingual abilities for billions of users.

<!--I am a Senior Research Scientist at [Noetica][noetica] at the intersection of fintech and legal tech, working on NLP tools used by (among others) four of the top five law firms in the world.

Previously, I was a research scientist at [Scaled Cognition][sc], where I developed rational, controllable AI models for high-trust scenarios.--> I earned my Ph.D. by introducing on structure-grounded translation and morphology techniques for 1,000+ languages. I also interned and published at Google, Duolingo, and Facebook. My Erdős number is <span title="me <-> Matula, David W. <-> Kučera, Luděk <-> Calkin, Neil J. <-> Erdős, Paul">4</span>. I invite you to explore my [publications](publications) (i.e., {{ site.data.publications | size }} peer-reviewed research papers and a book).

<!--
## News

- **October 2023.** I've defended and submitted my dissertation, [_Structured Analysis and Translation of Thousands of Languages_](https://jscholarship.library.jhu.edu/items/6d8993a9-321e-40d6-987e-2b62dfd4b372).
- **October 2023.** We've published the first application of FSTs to LLMs: "[Long-Form Speech Translation through Segmentation with Finite-State Decoding Constraints on Large Language Models](https://arxiv.org/abs/2310.13678)"
- **July 2023.** Our paper earned honorable mention for best paper at ACL 2023: "[Theory-Grounded Computational Text Analysis](https://aclanthology.org/2023.acl-short.136/)".
- **May 2023.** Our book on NLP methods in social science is published: *[A Free Press, If You Can Keep It: What Natural Language Processing Reveals About Freedom of the Press in Hong Kong](https://link.springer.com/book/10.1007/978-3-031-27584-5)*.
- **March 2023.** Led [panel discussion on integrating textual and non-textual data](https://cassandra.cs.jhu.edu/roundtables/mit/) at MIT.
- **February 2023.** Led [panel discussion on LLMs and the future of data](https://cassandra.cs.jhu.edu/roundtables/berkeley/) at UC Berkeley.
- **February 2023.** Gave [a talk at Columbia University](http://www.cs.columbia.edu/nlp/nlp_seminar.html) on translation at the scale of 1000+ languages.
- **January 2023.** Check out our new EACL paper: "[Meeting the needs of low-resource languages: The value of automatic alignments via pretrained models](https://aclanthology.org/2023.eacl-main.280/)"
- **December 2022.** Gave a talk at the Allen Institute for AI (AI2).
- **October 2022.** Check out our new EMNLP 2022 paper: "[A Major Obstacle for NLP Research: Let’s Talk about Time Allocation!](https://aclanthology.org/2022.emnlp-main.612/)"
- **October 2022.** Presented "[Deciphering and characterizing out-of-vocabulary words in morphologically rich languages](https://aclanthology.org/2022.coling-1.472/)" at COLING 2022 in Korea.
- **September 2022.** Gave a talk at UC Berkeley.
- **September 2022.** Gave a talk at Stanford University.
-->

## Music

I've played the bagpipe for over a decade. These days, it's a great way to social-distance. I also typeset original bagpipe compositions in LaTeX, which is criminally underestimated as a tool for bringing beauty into the world.

## Academic

I completed my Ph.D. at [Johns Hopkins University](https://www.jhu.edu), designing [machine translation](https://en.wikipedia.org/wiki/Machine_translation) that uses [panlingual weak supervision](https://aclanthology.org/2020.lrec-1.352/) with [David Yarowsky](https://www.cs.jhu.edu/faculty/david-yarowsky/)<!-- in JHU's [LoReLab](https://www.cs.jhu.edu/~arya/yarowsky-lab/)-->. 
<!--I was an [Amazon Fellow](https://ai2ai.engineering.jhu.edu/2022-2023-ai2ai-fellows/) and the 2022–2023 [Frederick Jelinek Fellow](https://www.clsp.jhu.edu/about/jelinek-fellowship/).-->
<!--I graduated from [SMU](https://en.wikipedia.org/wiki/Southern_Methodist_University) in 2017 with a bachelor's in mathematics and computer science and a master's in computer science. There, I worked with [David Matula](http://lyle.smu.edu/~matula/) on convex optimization, graph theory, and number theory.-->
In my master's, I worked with [David Matula](http://lyle.smu.edu/~matula/) on convex optimization, graph theory, and number theory.
My NLP life began as a [visiting researcher](https://uraf.harvard.edu/amgen-scholars) at Harvard, working with [Stuart Shieber](https://www.eecs.harvard.edu/shieber/) .
Along the way, I studied at [Stanford University](https://www.stanford.edu) and the [University of Edinburgh](https://www.ed.ac.uk).

### Selected publications:

* [On the uncomputability of partition functions in energy-based sequence models](https://openreview.net/forum?id=SsPCtEY6yCl) with Chu-Cheng Lin. ICLR 2022 Spotlight.
* [Addressing posterior collapse with mutual information for improved variational neural machine translation](http://dx.doi.org/10.18653/v1/2020.acl-main.753) with Xian Li, Jiatao Gu, and Ning Dong. ACL 2020.
* [Modeling color terminology across thousands of languages](http://dx.doi.org/10.18653/v1/D19-1229) with Winston Wu, Aaron Mueller, William Watson, and David Yarowsky. EMNLP 2019.

[See all {{ site.data.publications | size }} publications...](publications)

## Beauty

[I can't feel anything but gratitude for every single moment of my stupid little life.](https://web.archive.org/web/20190723152726/http://philhaverstick.com/8-09-02.html) Friends and strangers on trains have shared their tenderness with me. Clinging to scaffolding in bell towers. Sloshing for miles through stormwater drains. Bridge-jumping into the cold night Charles River. Mountainside sunrises in New Mexico. Jumping over filched restaurant candles for Charshanbe Suri. The world keeps rekindling things you didn't know had gone out.

<!--For graduate students: I encourage you to do one thing when you travel to conferences. Stay a few extra days. Push back your return flight, and take in the area's UNESCO World Heritage Sites and museums. Let the place have you for a little while longer.-->

[1]: https://scholar.google.com/citations?user=erysFsoAAAAJ&hl=en&oi=ao
[sc]: https://scaledcognition.com
[noetica]: https://www.noetica.ai
