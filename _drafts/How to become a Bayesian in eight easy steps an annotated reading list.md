# How to become a Bayesian in eight easy steps: an annotated reading list

First reading: Lindley. P-values rely on some nonexistent possible future trials. Bayesian is comparative against other hypotheses.
 
Second reading: Kruschke. Bayesian is about reallocation of probability among world states, ie different thetas. Some hypotheses (again, thetas) become less credible. 

Third reading: Dienes. Frequentist vs Bayesian. Frequentism (orthodoxy) doesn’t let you discuss $p(theory | data)$, which is more important to researchers. These are different—sharks biting heads off as a hypothesis for deadness. 
Also, Bayesian gives you three nice things.
* Stopping rules: you don’t need to specify in advance how data will be collected. P-values don’t move deterministically in one direction because of more trials. With enough participants, you’ll eventually reach significance. Bayesian instead lets you stop whenever. 
* You don’t need to formulate hypotheses in advance. You can test multiple hypotheses on one data set. Still—“cherry picking is wrong on all statistical approaches” (Dienes, 2011, p. 280).

Fourth reading: Rouder et al. Bayesian is symmetric, letting you not just reject but accept. Jeffreys gives ranges of Bayes factors. 1-3 is inconclusive. 3-10 is weak. 10+ is strong. But it’s all degree, not category. Don’t demand a strict line at 10 or something.

More parameters let you fit better. Use something like AIC or BIC to include a trade off between goodness of fit and parsimony of the model.  Except don’t. They don’t include the complexity of the model specification.

 https://files.osf.io/v1/resources/8wkpd/providers/osfstorage/57ca17196c613b01e924a909?action=download&version=4&direct