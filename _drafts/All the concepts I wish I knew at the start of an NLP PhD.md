---
layout: post
---

# All the concepts I wish I knew at the start of an NLP PhD

- Embeddings
- Kullback–Leibler divergence
- Softmax
- Gibbs sampling in NLP
- Expectation–Maximization (EM)—more than just counting things
- Generative model (vs discriminative)
- Generative adversarial network (GAN)
